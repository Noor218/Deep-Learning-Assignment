{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Concrete_strength_prediction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtYt54qvZZx5"
      },
      "source": [
        "**Assignment: Compresive Strength Concrete Problem**\n",
        "\n",
        "**Abstract:**\n",
        "\n",
        "Concrete is the most important material in civil engineering. The concrete compressive strength (concrete strength to bear the load) is a highly nonlinear function of age and ingredients.\n",
        "\n",
        "**WORKFLOW :**\n",
        "Load Data\n",
        "\n",
        "Check Missing Values ( If Exist ; Fill each record with mean of its feature )\n",
        "\n",
        "Standardized the Input Variables. Hint: Centeralized the data\n",
        "Split into 50% Training(Samples,Labels) , 30% Test(Samples,Labels) and 20% Validation Data(Samples,Labels).\n",
        "\n",
        "Model : input Layer (No. of features ), 3 hidden layers including 10,8,6 unit & Output Layer with activation function relu/tanh (check by experiment).\n",
        "\n",
        "Compilation Step (Note : Its a Regression problem , select loss , metrics according to it)\n",
        "\n",
        "Train the Model with Epochs (100) and validate it\n",
        "\n",
        "If the model gets overfit tune your model by changing the units , No. of layers , activation function , epochs , add dropout layer or add Regularizer according to the need .\n",
        "\n",
        "Evaluation Step\n",
        "\n",
        "Prediction\n",
        "\n",
        "**Load Data:**\n",
        "\n",
        "[Click Here to Download DataSet](https://github.com/ramsha275/ML_Datasets/blob/main/compresive_strength_concrete.csv)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBy7CkhhXQ_d"
      },
      "source": [
        "#import all required libraries \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from keras import models,layers"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "jDrTs9tfXsYC",
        "outputId": "bb69d511-9893-44e2-82d8-aad889a93147"
      },
      "source": [
        "#to upload the Datset File that we use in training\n",
        "from google.colab import files\n",
        "upload=files.upload()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-edd5753c-1900-4fec-a674-e9ae9acbfef5\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-edd5753c-1900-4fec-a674-e9ae9acbfef5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving compresive_strength_concrete.csv to compresive_strength_concrete.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "Vyx_bbeCYE6S",
        "outputId": "8d2bf332-649f-432f-9fd3-a3ee9dcba346"
      },
      "source": [
        "df=pd.read_csv('/content/compresive_strength_concrete.csv')#reading the file \n",
        "df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Cement (component 1)(kg in a m^3 mixture)</th>\n",
              "      <th>Blast Furnace Slag (component 2)(kg in a m^3 mixture)</th>\n",
              "      <th>Fly Ash (component 3)(kg in a m^3 mixture)</th>\n",
              "      <th>Water  (component 4)(kg in a m^3 mixture)</th>\n",
              "      <th>Superplasticizer (component 5)(kg in a m^3 mixture)</th>\n",
              "      <th>Coarse Aggregate  (component 6)(kg in a m^3 mixture)</th>\n",
              "      <th>Fine Aggregate (component 7)(kg in a m^3 mixture)</th>\n",
              "      <th>Age (day)</th>\n",
              "      <th>Concrete compressive strength(MPa, megapascals)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>540.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>1040.0</td>\n",
              "      <td>676.0</td>\n",
              "      <td>28</td>\n",
              "      <td>79.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>540.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>1055.0</td>\n",
              "      <td>676.0</td>\n",
              "      <td>28</td>\n",
              "      <td>61.89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>332.5</td>\n",
              "      <td>142.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>228.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>932.0</td>\n",
              "      <td>594.0</td>\n",
              "      <td>270</td>\n",
              "      <td>40.27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>332.5</td>\n",
              "      <td>142.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>228.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>932.0</td>\n",
              "      <td>594.0</td>\n",
              "      <td>365</td>\n",
              "      <td>41.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>198.6</td>\n",
              "      <td>132.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>192.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>978.4</td>\n",
              "      <td>825.5</td>\n",
              "      <td>360</td>\n",
              "      <td>44.30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Cement (component 1)(kg in a m^3 mixture)  ...  Concrete compressive strength(MPa, megapascals) \n",
              "0                                      540.0  ...                                             79.99\n",
              "1                                      540.0  ...                                             61.89\n",
              "2                                      332.5  ...                                             40.27\n",
              "3                                      332.5  ...                                             41.05\n",
              "4                                      198.6  ...                                             44.30\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C54tXgDxZB04",
        "outputId": "35cffbaf-0228-44a7-a094-44a2f02d8d3f"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1030 entries, 0 to 1029\n",
            "Data columns (total 9 columns):\n",
            " #   Column                                                 Non-Null Count  Dtype  \n",
            "---  ------                                                 --------------  -----  \n",
            " 0   Cement (component 1)(kg in a m^3 mixture)              1030 non-null   float64\n",
            " 1   Blast Furnace Slag (component 2)(kg in a m^3 mixture)  1030 non-null   float64\n",
            " 2   Fly Ash (component 3)(kg in a m^3 mixture)             1030 non-null   float64\n",
            " 3   Water  (component 4)(kg in a m^3 mixture)              1030 non-null   float64\n",
            " 4   Superplasticizer (component 5)(kg in a m^3 mixture)    1030 non-null   float64\n",
            " 5   Coarse Aggregate  (component 6)(kg in a m^3 mixture)   1030 non-null   float64\n",
            " 6   Fine Aggregate (component 7)(kg in a m^3 mixture)      1030 non-null   float64\n",
            " 7   Age (day)                                              1030 non-null   int64  \n",
            " 8   Concrete compressive strength(MPa, megapascals)        1030 non-null   float64\n",
            "dtypes: float64(8), int64(1)\n",
            "memory usage: 72.5 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FV_vEzwafWy"
      },
      "source": [
        "df['Age (day)']=df.select_dtypes('int64').astype('float64')#converting age column to float64"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CUKfT8ncXd4"
      },
      "source": [
        "test_val=(30/100)*len(df)#get the value that r 30% of Dataset\n",
        "train_val=(50/100)*len(df)#get the value that r 50% of Dataset\n",
        "val_val=(20/100)*len(df)#get the value that r 20% of Dataset\n",
        "\n",
        "test_data=df.loc[len(df)-test_val: ,:'Age (day)']#separating the test data from dataset, pick the data from last of dataset\n",
        "test_labels=df.loc[len(df)-test_val: ,'Concrete compressive strength(MPa, megapascals) ']#separating the test labels from dataset\n",
        "\n",
        "remaining_data=df.loc[:len(df)-test_val,:'Age (day)']#to store the remaing datset for further processing\n",
        "remaining_labels=df.loc[:len(df)-test_val,'Concrete compressive strength(MPa, megapascals) ']\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6b_hZxnfBMu"
      },
      "source": [
        "mean=df.mean(axis=0)\n",
        "std=df.std(axis=0)\n",
        "\n",
        "remaining_data-=mean\n",
        "remaining_data/=std\n",
        "\n",
        "test_data-=mean\n",
        "test_data/=std"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYXojbipqKJ2"
      },
      "source": [
        "train_data = remaining_data.loc[ :test_val]\n",
        "train_labels = remaining_labels.loc[ :test_val]\n",
        "\n",
        "val_data=remaining_data.loc[test_val:]\n",
        "val_labels=remaining_labels.loc[test_val:]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRXi36ndf8Je"
      },
      "source": [
        "model=models.Sequential()\n",
        "model.add(layers.Dense(36,activation='relu',input_shape=(8,)))\n",
        "model.add(layers.Dense(36,activation='relu'))\n",
        "model.add(layers.Dense(1))\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MLdRkYNgfWv"
      },
      "source": [
        "model.compile(optimizer='rmsprop',loss='mse',metrics=['mae'])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vi6VN96dizvs",
        "outputId": "0522eb94-a908-4c94-982d-f8d34e8b4932"
      },
      "source": [
        "model.fit(train_data,train_labels,epochs=150,batch_size=100,validation_data=(val_data,val_labels))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "4/4 [==============================] - 1s 161ms/step - loss: 2189.2393 - mae: 43.2234 - val_loss: 1394.7069 - val_mae: 33.4158\n",
            "Epoch 2/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 2179.3166 - mae: 43.0780 - val_loss: 1379.5189 - val_mae: 33.1999\n",
            "Epoch 3/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 2073.6135 - mae: 41.9523 - val_loss: 1366.3468 - val_mae: 33.0098\n",
            "Epoch 4/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 2022.6482 - mae: 41.3610 - val_loss: 1353.9609 - val_mae: 32.8323\n",
            "Epoch 5/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 2052.8553 - mae: 41.6150 - val_loss: 1341.7311 - val_mae: 32.6516\n",
            "Epoch 6/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 2042.6364 - mae: 41.4431 - val_loss: 1328.8654 - val_mae: 32.4640\n",
            "Epoch 7/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 2009.7843 - mae: 41.2977 - val_loss: 1315.6144 - val_mae: 32.2700\n",
            "Epoch 8/150\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 1990.3688 - mae: 41.0418 - val_loss: 1302.9026 - val_mae: 32.0817\n",
            "Epoch 9/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 1947.6829 - mae: 40.3100 - val_loss: 1289.3302 - val_mae: 31.8812\n",
            "Epoch 10/150\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 1980.4309 - mae: 40.9418 - val_loss: 1275.7678 - val_mae: 31.6793\n",
            "Epoch 11/150\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 1885.4624 - mae: 39.7527 - val_loss: 1261.5729 - val_mae: 31.4700\n",
            "Epoch 12/150\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 1920.4267 - mae: 40.2873 - val_loss: 1247.3271 - val_mae: 31.2565\n",
            "Epoch 13/150\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 1876.3205 - mae: 39.6435 - val_loss: 1232.8534 - val_mae: 31.0376\n",
            "Epoch 14/150\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 1880.7552 - mae: 39.7058 - val_loss: 1217.1283 - val_mae: 30.7994\n",
            "Epoch 15/150\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 1754.7787 - mae: 38.1927 - val_loss: 1200.3972 - val_mae: 30.5435\n",
            "Epoch 16/150\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 1773.9542 - mae: 38.6413 - val_loss: 1183.3936 - val_mae: 30.2844\n",
            "Epoch 17/150\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 1782.9329 - mae: 38.6142 - val_loss: 1166.3527 - val_mae: 30.0228\n",
            "Epoch 18/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 1686.2222 - mae: 37.4012 - val_loss: 1148.9646 - val_mae: 29.7560\n",
            "Epoch 19/150\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 1670.2917 - mae: 37.3235 - val_loss: 1131.7898 - val_mae: 29.4871\n",
            "Epoch 20/150\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 1633.8774 - mae: 37.0347 - val_loss: 1113.1469 - val_mae: 29.1966\n",
            "Epoch 21/150\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1565.5847 - mae: 36.0688 - val_loss: 1094.5961 - val_mae: 28.9032\n",
            "Epoch 22/150\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 1544.8917 - mae: 35.6233 - val_loss: 1075.5692 - val_mae: 28.6004\n",
            "Epoch 23/150\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 1524.2281 - mae: 35.5526 - val_loss: 1055.6458 - val_mae: 28.2774\n",
            "Epoch 24/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 1435.5292 - mae: 34.4719 - val_loss: 1036.3949 - val_mae: 27.9633\n",
            "Epoch 25/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 1451.9940 - mae: 34.5962 - val_loss: 1014.0347 - val_mae: 27.5996\n",
            "Epoch 26/150\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 1334.3061 - mae: 33.0767 - val_loss: 992.2938 - val_mae: 27.2412\n",
            "Epoch 27/150\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 1346.9582 - mae: 33.2057 - val_loss: 970.9208 - val_mae: 26.8823\n",
            "Epoch 28/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 1242.6468 - mae: 31.8576 - val_loss: 950.3911 - val_mae: 26.5363\n",
            "Epoch 29/150\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 1214.6927 - mae: 31.6343 - val_loss: 929.2968 - val_mae: 26.1757\n",
            "Epoch 30/150\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 1191.5832 - mae: 30.9657 - val_loss: 906.9216 - val_mae: 25.7904\n",
            "Epoch 31/150\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 1138.3356 - mae: 30.2950 - val_loss: 883.3737 - val_mae: 25.3794\n",
            "Epoch 32/150\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 1153.8178 - mae: 30.3078 - val_loss: 861.7505 - val_mae: 24.9927\n",
            "Epoch 33/150\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 1098.8981 - mae: 29.4575 - val_loss: 838.5761 - val_mae: 24.5769\n",
            "Epoch 34/150\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 1011.7627 - mae: 28.1347 - val_loss: 816.1702 - val_mae: 24.1682\n",
            "Epoch 35/150\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 973.6226 - mae: 27.4255 - val_loss: 793.0683 - val_mae: 23.7431\n",
            "Epoch 36/150\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 916.7597 - mae: 26.5087 - val_loss: 769.6992 - val_mae: 23.3031\n",
            "Epoch 37/150\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 882.2851 - mae: 25.9332 - val_loss: 744.1069 - val_mae: 22.8155\n",
            "Epoch 38/150\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 830.4727 - mae: 24.9568 - val_loss: 722.0436 - val_mae: 22.3800\n",
            "Epoch 39/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 808.9760 - mae: 24.5112 - val_loss: 696.9058 - val_mae: 21.8810\n",
            "Epoch 40/150\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 758.4110 - mae: 23.6425 - val_loss: 675.7275 - val_mae: 21.4625\n",
            "Epoch 41/150\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 692.6019 - mae: 22.4214 - val_loss: 651.8156 - val_mae: 20.9871\n",
            "Epoch 42/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 681.3046 - mae: 22.0323 - val_loss: 631.0767 - val_mae: 20.5794\n",
            "Epoch 43/150\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 632.9391 - mae: 21.1376 - val_loss: 607.2126 - val_mae: 20.1134\n",
            "Epoch 44/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 607.1318 - mae: 20.6577 - val_loss: 587.0579 - val_mae: 19.7098\n",
            "Epoch 45/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 576.4586 - mae: 20.0896 - val_loss: 565.5876 - val_mae: 19.2727\n",
            "Epoch 46/150\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 524.8713 - mae: 18.9533 - val_loss: 542.9031 - val_mae: 18.8076\n",
            "Epoch 47/150\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 528.8588 - mae: 19.1269 - val_loss: 522.7577 - val_mae: 18.4138\n",
            "Epoch 48/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 483.6596 - mae: 18.1376 - val_loss: 500.2016 - val_mae: 17.9734\n",
            "Epoch 49/150\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 447.7559 - mae: 17.6159 - val_loss: 480.1851 - val_mae: 17.5711\n",
            "Epoch 50/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 437.9353 - mae: 17.2754 - val_loss: 465.8027 - val_mae: 17.2759\n",
            "Epoch 51/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 406.7231 - mae: 16.7784 - val_loss: 449.6777 - val_mae: 16.9465\n",
            "Epoch 52/150\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 418.6554 - mae: 16.8546 - val_loss: 436.7211 - val_mae: 16.6762\n",
            "Epoch 53/150\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 389.1086 - mae: 16.2060 - val_loss: 419.0360 - val_mae: 16.3086\n",
            "Epoch 54/150\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 364.6508 - mae: 15.5759 - val_loss: 402.2439 - val_mae: 15.9702\n",
            "Epoch 55/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 347.8133 - mae: 15.1295 - val_loss: 390.3743 - val_mae: 15.7223\n",
            "Epoch 56/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 356.1501 - mae: 15.4540 - val_loss: 376.2726 - val_mae: 15.4304\n",
            "Epoch 57/150\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 361.6175 - mae: 15.5611 - val_loss: 363.7366 - val_mae: 15.1618\n",
            "Epoch 58/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 348.5698 - mae: 15.4895 - val_loss: 360.1531 - val_mae: 15.0816\n",
            "Epoch 59/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 344.1879 - mae: 15.1425 - val_loss: 348.1115 - val_mae: 14.8127\n",
            "Epoch 60/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 331.2805 - mae: 14.7119 - val_loss: 339.7116 - val_mae: 14.6269\n",
            "Epoch 61/150\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 311.4575 - mae: 14.4234 - val_loss: 327.6657 - val_mae: 14.3672\n",
            "Epoch 62/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 305.6755 - mae: 14.3637 - val_loss: 323.3582 - val_mae: 14.2732\n",
            "Epoch 63/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 297.6155 - mae: 14.0893 - val_loss: 317.8148 - val_mae: 14.1525\n",
            "Epoch 64/150\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 284.2360 - mae: 13.7576 - val_loss: 312.9830 - val_mae: 14.0483\n",
            "Epoch 65/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 283.8058 - mae: 13.8081 - val_loss: 301.7733 - val_mae: 13.8029\n",
            "Epoch 66/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 290.0856 - mae: 13.8673 - val_loss: 291.4727 - val_mae: 13.5670\n",
            "Epoch 67/150\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 270.4024 - mae: 13.2863 - val_loss: 283.6669 - val_mae: 13.3968\n",
            "Epoch 68/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 276.1233 - mae: 13.5355 - val_loss: 279.8661 - val_mae: 13.3130\n",
            "Epoch 69/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 245.4966 - mae: 12.7085 - val_loss: 270.5477 - val_mae: 13.0915\n",
            "Epoch 70/150\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 248.9400 - mae: 12.8064 - val_loss: 261.9540 - val_mae: 12.8878\n",
            "Epoch 71/150\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 255.5370 - mae: 13.1580 - val_loss: 259.8904 - val_mae: 12.8398\n",
            "Epoch 72/150\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 235.4985 - mae: 12.7049 - val_loss: 254.9497 - val_mae: 12.7288\n",
            "Epoch 73/150\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 233.7653 - mae: 12.5930 - val_loss: 249.7074 - val_mae: 12.6164\n",
            "Epoch 74/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 237.8255 - mae: 12.6869 - val_loss: 249.7072 - val_mae: 12.6167\n",
            "Epoch 75/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 233.4856 - mae: 12.6020 - val_loss: 245.7959 - val_mae: 12.5200\n",
            "Epoch 76/150\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 227.6415 - mae: 12.3387 - val_loss: 243.4938 - val_mae: 12.4736\n",
            "Epoch 77/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 226.6292 - mae: 12.5302 - val_loss: 245.3365 - val_mae: 12.5174\n",
            "Epoch 78/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 217.4311 - mae: 12.1863 - val_loss: 243.2957 - val_mae: 12.4715\n",
            "Epoch 79/150\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 216.9671 - mae: 12.0842 - val_loss: 243.3885 - val_mae: 12.4865\n",
            "Epoch 80/150\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 216.4406 - mae: 12.1534 - val_loss: 243.8770 - val_mae: 12.4926\n",
            "Epoch 81/150\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 207.3246 - mae: 11.9033 - val_loss: 242.2365 - val_mae: 12.4632\n",
            "Epoch 82/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 210.1007 - mae: 11.9896 - val_loss: 241.3477 - val_mae: 12.4403\n",
            "Epoch 83/150\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 203.3736 - mae: 11.7417 - val_loss: 239.6382 - val_mae: 12.4120\n",
            "Epoch 84/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 204.2724 - mae: 11.7640 - val_loss: 234.1691 - val_mae: 12.3017\n",
            "Epoch 85/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 203.1291 - mae: 11.6958 - val_loss: 229.8735 - val_mae: 12.2095\n",
            "Epoch 86/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 191.6902 - mae: 11.3584 - val_loss: 234.6703 - val_mae: 12.3116\n",
            "Epoch 87/150\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 206.1487 - mae: 11.8422 - val_loss: 231.6419 - val_mae: 12.2508\n",
            "Epoch 88/150\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 200.1682 - mae: 11.6859 - val_loss: 233.0182 - val_mae: 12.2867\n",
            "Epoch 89/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 204.8522 - mae: 11.7920 - val_loss: 230.0377 - val_mae: 12.2240\n",
            "Epoch 90/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 189.3028 - mae: 11.3573 - val_loss: 232.4649 - val_mae: 12.2790\n",
            "Epoch 91/150\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 201.6963 - mae: 11.7882 - val_loss: 229.2018 - val_mae: 12.2148\n",
            "Epoch 92/150\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 190.9432 - mae: 11.3744 - val_loss: 229.6833 - val_mae: 12.2210\n",
            "Epoch 93/150\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 181.8999 - mae: 11.1535 - val_loss: 229.3524 - val_mae: 12.2083\n",
            "Epoch 94/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 188.5211 - mae: 11.3717 - val_loss: 229.2663 - val_mae: 12.2121\n",
            "Epoch 95/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 181.9238 - mae: 11.1608 - val_loss: 231.3258 - val_mae: 12.2622\n",
            "Epoch 96/150\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 194.1656 - mae: 11.5438 - val_loss: 229.8324 - val_mae: 12.2371\n",
            "Epoch 97/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 179.6274 - mae: 11.0222 - val_loss: 228.5925 - val_mae: 12.2171\n",
            "Epoch 98/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 191.1320 - mae: 11.5312 - val_loss: 232.0090 - val_mae: 12.2956\n",
            "Epoch 99/150\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 179.8990 - mae: 11.0483 - val_loss: 230.5218 - val_mae: 12.2672\n",
            "Epoch 100/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 168.6720 - mae: 10.7102 - val_loss: 233.8716 - val_mae: 12.3565\n",
            "Epoch 101/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 173.2044 - mae: 10.8476 - val_loss: 235.7014 - val_mae: 12.3961\n",
            "Epoch 102/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 176.9281 - mae: 10.9502 - val_loss: 234.3018 - val_mae: 12.3643\n",
            "Epoch 103/150\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 174.7167 - mae: 10.9290 - val_loss: 235.1880 - val_mae: 12.3816\n",
            "Epoch 104/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 164.5665 - mae: 10.6392 - val_loss: 233.1672 - val_mae: 12.3432\n",
            "Epoch 105/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 169.2412 - mae: 10.7499 - val_loss: 235.1159 - val_mae: 12.3889\n",
            "Epoch 106/150\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 184.0107 - mae: 11.2465 - val_loss: 235.8561 - val_mae: 12.4022\n",
            "Epoch 107/150\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 176.1961 - mae: 11.0012 - val_loss: 231.5710 - val_mae: 12.3159\n",
            "Epoch 108/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 167.6576 - mae: 10.6811 - val_loss: 228.3929 - val_mae: 12.2507\n",
            "Epoch 109/150\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 172.3751 - mae: 10.8585 - val_loss: 227.1012 - val_mae: 12.2242\n",
            "Epoch 110/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 170.4259 - mae: 10.8369 - val_loss: 229.0406 - val_mae: 12.2711\n",
            "Epoch 111/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 161.7631 - mae: 10.4808 - val_loss: 227.6381 - val_mae: 12.2474\n",
            "Epoch 112/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 164.1584 - mae: 10.6264 - val_loss: 228.4698 - val_mae: 12.2725\n",
            "Epoch 113/150\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 168.8299 - mae: 10.8100 - val_loss: 233.7863 - val_mae: 12.3839\n",
            "Epoch 114/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 164.6431 - mae: 10.5880 - val_loss: 233.0561 - val_mae: 12.3711\n",
            "Epoch 115/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 161.7069 - mae: 10.4908 - val_loss: 235.4336 - val_mae: 12.4314\n",
            "Epoch 116/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 162.3997 - mae: 10.4885 - val_loss: 235.3307 - val_mae: 12.4326\n",
            "Epoch 117/150\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 161.9443 - mae: 10.5797 - val_loss: 235.1688 - val_mae: 12.4221\n",
            "Epoch 118/150\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 155.7092 - mae: 10.2203 - val_loss: 234.5457 - val_mae: 12.4128\n",
            "Epoch 119/150\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 160.9169 - mae: 10.4399 - val_loss: 235.0815 - val_mae: 12.4330\n",
            "Epoch 120/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 159.6616 - mae: 10.4292 - val_loss: 236.3461 - val_mae: 12.4476\n",
            "Epoch 121/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 162.1226 - mae: 10.4818 - val_loss: 232.3260 - val_mae: 12.3736\n",
            "Epoch 122/150\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 155.1256 - mae: 10.2515 - val_loss: 232.5162 - val_mae: 12.3830\n",
            "Epoch 123/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 157.1175 - mae: 10.2420 - val_loss: 233.8170 - val_mae: 12.4175\n",
            "Epoch 124/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 157.5523 - mae: 10.2985 - val_loss: 233.4063 - val_mae: 12.4241\n",
            "Epoch 125/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 160.7114 - mae: 10.4975 - val_loss: 234.2394 - val_mae: 12.4457\n",
            "Epoch 126/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 155.8791 - mae: 10.2955 - val_loss: 238.3896 - val_mae: 12.5425\n",
            "Epoch 127/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 158.3347 - mae: 10.4758 - val_loss: 235.8865 - val_mae: 12.5006\n",
            "Epoch 128/150\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 153.5367 - mae: 10.2258 - val_loss: 235.9782 - val_mae: 12.4884\n",
            "Epoch 129/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 153.6460 - mae: 10.2429 - val_loss: 238.0326 - val_mae: 12.5187\n",
            "Epoch 130/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 151.7090 - mae: 10.1171 - val_loss: 234.8176 - val_mae: 12.4600\n",
            "Epoch 131/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 156.2147 - mae: 10.2980 - val_loss: 233.8460 - val_mae: 12.4489\n",
            "Epoch 132/150\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 149.6650 - mae: 10.0792 - val_loss: 233.5829 - val_mae: 12.4469\n",
            "Epoch 133/150\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 156.1846 - mae: 10.2601 - val_loss: 233.9145 - val_mae: 12.4630\n",
            "Epoch 134/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 146.4688 - mae: 9.9310 - val_loss: 236.5402 - val_mae: 12.5105\n",
            "Epoch 135/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 154.5690 - mae: 10.2381 - val_loss: 236.3916 - val_mae: 12.5089\n",
            "Epoch 136/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 149.3351 - mae: 9.9808 - val_loss: 238.2824 - val_mae: 12.5567\n",
            "Epoch 137/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 140.2632 - mae: 9.7178 - val_loss: 237.7066 - val_mae: 12.5436\n",
            "Epoch 138/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 144.9713 - mae: 9.8952 - val_loss: 238.0495 - val_mae: 12.5483\n",
            "Epoch 139/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 146.6045 - mae: 9.9485 - val_loss: 235.9840 - val_mae: 12.5031\n",
            "Epoch 140/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 144.6607 - mae: 9.7774 - val_loss: 240.5762 - val_mae: 12.5961\n",
            "Epoch 141/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 143.9549 - mae: 9.8153 - val_loss: 239.7165 - val_mae: 12.5847\n",
            "Epoch 142/150\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 154.2483 - mae: 10.1918 - val_loss: 238.8263 - val_mae: 12.5712\n",
            "Epoch 143/150\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 148.5671 - mae: 9.8815 - val_loss: 239.0671 - val_mae: 12.5864\n",
            "Epoch 144/150\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 145.0130 - mae: 9.8972 - val_loss: 239.5559 - val_mae: 12.5892\n",
            "Epoch 145/150\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 148.6758 - mae: 10.0107 - val_loss: 242.2860 - val_mae: 12.6504\n",
            "Epoch 146/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 141.4560 - mae: 9.7581 - val_loss: 241.8568 - val_mae: 12.6652\n",
            "Epoch 147/150\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 147.8554 - mae: 9.9963 - val_loss: 239.2504 - val_mae: 12.6003\n",
            "Epoch 148/150\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 143.9609 - mae: 9.7162 - val_loss: 239.7389 - val_mae: 12.6037\n",
            "Epoch 149/150\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 134.6926 - mae: 9.4622 - val_loss: 240.4779 - val_mae: 12.6120\n",
            "Epoch 150/150\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 142.5437 - mae: 9.7360 - val_loss: 240.1042 - val_mae: 12.6052\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f962c85a2d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlPKCWFVsNRX"
      },
      "source": [
        "def build_model():\n",
        "  model=models.Sequential()\n",
        "  model.add(layers.Dense(36,activation='relu',input_shape=(8,)))\n",
        "  model.add(layers.Dense(36,activation='relu'))\n",
        "  model.add(layers.Dense(1))\n",
        "  model.compile(optimizer='rmsprop',loss='mse',metrics=['mae'])\n",
        "  return model"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DWNoyy3qvDV",
        "outputId": "effb7aeb-ab08-4b58-8531-b160825bf719"
      },
      "source": [
        "k = 4\n",
        "num_val_samples = len(remaining_data) // k\n",
        "num_epochs = 80\n",
        "all_mae_histories = []\n",
        "for i in range(k):\n",
        " print('processing fold #', i)\n",
        "\n",
        " # Prepare the validation data: data from partition # k\n",
        " val_data = remaining_data[i * num_val_samples: (i + 1) * num_val_samples]\n",
        " val_targets = remaining_labels[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "\n",
        "\n",
        " # Prepare the training data: data from all other partitions\n",
        " partial_train_data = np.concatenate([remaining_data[:i * num_val_samples],remaining_data[(i + 1) * num_val_samples:]],axis=0)\n",
        " partial_train_targets = np.concatenate([remaining_labels[:i * num_val_samples],remaining_labels[(i + 1) * num_val_samples:]],axis=0)\n",
        " # Build the Keras model (already compiled)\n",
        "\n",
        "\n",
        " model = build_model()\n",
        " # Train the model (in silent mode, verbose=0)\n",
        " history = model.fit(partial_train_data, partial_train_targets,validation_data=(val_data, val_targets),epochs=num_epochs, batch_size=5)\n",
        " mae_history = history.history['val_mae']\n",
        " all_mae_histories.append(mae_history)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processing fold # 0\n",
            "Epoch 1/80\n",
            "109/109 [==============================] - 1s 3ms/step - loss: 1239.3618 - mae: 31.2900 - val_loss: 1911.0229 - val_mae: 40.6310\n",
            "Epoch 2/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 612.9535 - mae: 19.9674 - val_loss: 928.6174 - val_mae: 25.8085\n",
            "Epoch 3/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 267.0385 - mae: 12.6650 - val_loss: 526.4664 - val_mae: 18.2416\n",
            "Epoch 4/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 200.7095 - mae: 10.9370 - val_loss: 427.7041 - val_mae: 16.8539\n",
            "Epoch 5/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 164.8756 - mae: 10.1977 - val_loss: 433.7340 - val_mae: 16.8193\n",
            "Epoch 6/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 144.9435 - mae: 9.5138 - val_loss: 454.9314 - val_mae: 16.7640\n",
            "Epoch 7/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 150.7544 - mae: 9.6427 - val_loss: 471.2066 - val_mae: 16.7642\n",
            "Epoch 8/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 127.0399 - mae: 8.7274 - val_loss: 466.3672 - val_mae: 16.6184\n",
            "Epoch 9/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 116.4118 - mae: 8.4936 - val_loss: 535.0639 - val_mae: 17.3897\n",
            "Epoch 10/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 108.1716 - mae: 8.1112 - val_loss: 491.9341 - val_mae: 16.8012\n",
            "Epoch 11/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 123.2226 - mae: 8.4945 - val_loss: 524.2436 - val_mae: 17.1613\n",
            "Epoch 12/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 109.7083 - mae: 8.0415 - val_loss: 490.8797 - val_mae: 16.8098\n",
            "Epoch 13/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 139.8023 - mae: 9.0070 - val_loss: 543.7389 - val_mae: 17.4789\n",
            "Epoch 14/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 117.7362 - mae: 8.3280 - val_loss: 550.2242 - val_mae: 17.4988\n",
            "Epoch 15/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 112.3674 - mae: 8.0625 - val_loss: 522.6263 - val_mae: 17.1577\n",
            "Epoch 16/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 97.0718 - mae: 7.6923 - val_loss: 565.4978 - val_mae: 17.7271\n",
            "Epoch 17/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 104.7062 - mae: 7.9278 - val_loss: 548.9379 - val_mae: 17.5673\n",
            "Epoch 18/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 112.6372 - mae: 7.8981 - val_loss: 501.5284 - val_mae: 16.8205\n",
            "Epoch 19/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 103.4098 - mae: 7.9336 - val_loss: 526.9602 - val_mae: 17.1519\n",
            "Epoch 20/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 114.8482 - mae: 7.9493 - val_loss: 579.5927 - val_mae: 17.8194\n",
            "Epoch 21/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 86.9244 - mae: 7.0296 - val_loss: 543.9202 - val_mae: 17.3245\n",
            "Epoch 22/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 100.7447 - mae: 7.5441 - val_loss: 586.3173 - val_mae: 17.9227\n",
            "Epoch 23/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 102.1357 - mae: 7.5544 - val_loss: 502.8020 - val_mae: 16.8239\n",
            "Epoch 24/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 113.8719 - mae: 7.8532 - val_loss: 647.7913 - val_mae: 18.7113\n",
            "Epoch 25/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 88.9436 - mae: 7.2338 - val_loss: 530.6121 - val_mae: 17.2189\n",
            "Epoch 26/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 91.5100 - mae: 7.1695 - val_loss: 570.2852 - val_mae: 17.7871\n",
            "Epoch 27/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 81.0029 - mae: 6.8457 - val_loss: 532.4361 - val_mae: 17.2940\n",
            "Epoch 28/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 97.5357 - mae: 7.3699 - val_loss: 569.2026 - val_mae: 17.7446\n",
            "Epoch 29/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 82.4570 - mae: 6.8960 - val_loss: 532.4939 - val_mae: 17.1679\n",
            "Epoch 30/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 96.4343 - mae: 7.1005 - val_loss: 593.3317 - val_mae: 17.9983\n",
            "Epoch 31/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 109.9100 - mae: 7.4543 - val_loss: 574.3688 - val_mae: 17.6478\n",
            "Epoch 32/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 84.4690 - mae: 6.6652 - val_loss: 506.6986 - val_mae: 16.8505\n",
            "Epoch 33/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 79.8317 - mae: 6.6917 - val_loss: 519.9080 - val_mae: 16.9360\n",
            "Epoch 34/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 89.7389 - mae: 7.1219 - val_loss: 504.6430 - val_mae: 16.8053\n",
            "Epoch 35/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 77.7004 - mae: 6.7476 - val_loss: 475.1075 - val_mae: 16.3860\n",
            "Epoch 36/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 72.9502 - mae: 6.7472 - val_loss: 512.9822 - val_mae: 17.0163\n",
            "Epoch 37/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 77.4930 - mae: 6.6898 - val_loss: 513.2582 - val_mae: 17.0313\n",
            "Epoch 38/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 84.0394 - mae: 6.9461 - val_loss: 497.2121 - val_mae: 16.6957\n",
            "Epoch 39/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 72.1920 - mae: 6.4692 - val_loss: 541.4068 - val_mae: 17.4114\n",
            "Epoch 40/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 79.0310 - mae: 6.5916 - val_loss: 475.2895 - val_mae: 16.3853\n",
            "Epoch 41/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 65.3695 - mae: 6.2117 - val_loss: 436.1625 - val_mae: 15.8227\n",
            "Epoch 42/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 64.1010 - mae: 6.2095 - val_loss: 409.2164 - val_mae: 15.3678\n",
            "Epoch 43/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 61.8164 - mae: 6.1277 - val_loss: 433.8091 - val_mae: 15.8004\n",
            "Epoch 44/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 66.9341 - mae: 6.1556 - val_loss: 412.0938 - val_mae: 15.4116\n",
            "Epoch 45/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 60.6124 - mae: 5.8862 - val_loss: 478.4305 - val_mae: 16.4771\n",
            "Epoch 46/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 52.1691 - mae: 5.6580 - val_loss: 399.2025 - val_mae: 15.1736\n",
            "Epoch 47/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 54.0638 - mae: 5.6591 - val_loss: 410.9260 - val_mae: 15.4208\n",
            "Epoch 48/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 54.3195 - mae: 5.7859 - val_loss: 352.4252 - val_mae: 14.3895\n",
            "Epoch 49/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 50.8229 - mae: 5.4181 - val_loss: 370.4133 - val_mae: 14.6694\n",
            "Epoch 50/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 47.6289 - mae: 5.2747 - val_loss: 354.1991 - val_mae: 14.3648\n",
            "Epoch 51/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 48.1112 - mae: 5.3964 - val_loss: 374.4667 - val_mae: 14.7581\n",
            "Epoch 52/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 51.3096 - mae: 5.4562 - val_loss: 388.2985 - val_mae: 15.0857\n",
            "Epoch 53/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 48.2762 - mae: 5.3170 - val_loss: 431.3540 - val_mae: 15.8633\n",
            "Epoch 54/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 38.1764 - mae: 4.8131 - val_loss: 323.4171 - val_mae: 13.8254\n",
            "Epoch 55/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 44.9549 - mae: 5.2463 - val_loss: 316.4457 - val_mae: 13.6931\n",
            "Epoch 56/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 36.9157 - mae: 4.6744 - val_loss: 307.9433 - val_mae: 13.4178\n",
            "Epoch 57/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 41.3204 - mae: 4.9155 - val_loss: 325.2928 - val_mae: 13.7941\n",
            "Epoch 58/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 34.8738 - mae: 4.5586 - val_loss: 297.3674 - val_mae: 13.2661\n",
            "Epoch 59/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 37.3802 - mae: 4.7134 - val_loss: 312.1678 - val_mae: 13.5975\n",
            "Epoch 60/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 38.0493 - mae: 4.6829 - val_loss: 329.8505 - val_mae: 13.9433\n",
            "Epoch 61/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 34.8128 - mae: 4.5080 - val_loss: 323.7770 - val_mae: 13.8354\n",
            "Epoch 62/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 31.5089 - mae: 4.2280 - val_loss: 311.6838 - val_mae: 13.6160\n",
            "Epoch 63/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 29.2463 - mae: 4.1907 - val_loss: 281.3927 - val_mae: 12.9920\n",
            "Epoch 64/80\n",
            "109/109 [==============================] - 0s 4ms/step - loss: 30.3924 - mae: 4.1437 - val_loss: 292.8123 - val_mae: 13.2214\n",
            "Epoch 65/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 29.9100 - mae: 4.1477 - val_loss: 319.3499 - val_mae: 13.7513\n",
            "Epoch 66/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 29.3566 - mae: 4.0333 - val_loss: 337.7913 - val_mae: 14.0838\n",
            "Epoch 67/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 31.3672 - mae: 4.1611 - val_loss: 250.7361 - val_mae: 12.3751\n",
            "Epoch 68/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 25.8080 - mae: 3.8271 - val_loss: 250.0314 - val_mae: 12.3479\n",
            "Epoch 69/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 24.6028 - mae: 3.8111 - val_loss: 291.1914 - val_mae: 13.2065\n",
            "Epoch 70/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 24.3294 - mae: 3.8163 - val_loss: 340.3775 - val_mae: 14.1155\n",
            "Epoch 71/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 23.2772 - mae: 3.6987 - val_loss: 271.0281 - val_mae: 12.7504\n",
            "Epoch 72/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 24.1738 - mae: 3.6603 - val_loss: 268.5345 - val_mae: 12.7212\n",
            "Epoch 73/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 26.1094 - mae: 3.8729 - val_loss: 306.5112 - val_mae: 13.5135\n",
            "Epoch 74/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 22.6435 - mae: 3.7667 - val_loss: 272.0250 - val_mae: 12.8157\n",
            "Epoch 75/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 23.3701 - mae: 3.6776 - val_loss: 262.7287 - val_mae: 12.5875\n",
            "Epoch 76/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 26.0107 - mae: 3.8533 - val_loss: 236.0020 - val_mae: 12.0216\n",
            "Epoch 77/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 21.0132 - mae: 3.3989 - val_loss: 281.9849 - val_mae: 12.9904\n",
            "Epoch 78/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 24.7396 - mae: 3.7172 - val_loss: 287.6597 - val_mae: 13.1463\n",
            "Epoch 79/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 24.7280 - mae: 3.6856 - val_loss: 247.6910 - val_mae: 12.3346\n",
            "Epoch 80/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 25.4809 - mae: 3.7202 - val_loss: 248.7163 - val_mae: 12.3473\n",
            "processing fold # 1\n",
            "Epoch 1/80\n",
            "109/109 [==============================] - 1s 3ms/step - loss: 1632.5631 - mae: 35.9563 - val_loss: 1090.2020 - val_mae: 29.8803\n",
            "Epoch 2/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 939.4901 - mae: 26.1010 - val_loss: 560.8132 - val_mae: 20.5666\n",
            "Epoch 3/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 327.4477 - mae: 14.2534 - val_loss: 268.2829 - val_mae: 13.8338\n",
            "Epoch 4/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 219.4445 - mae: 12.2350 - val_loss: 197.6536 - val_mae: 11.7729\n",
            "Epoch 5/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 174.9369 - mae: 10.7941 - val_loss: 171.0538 - val_mae: 10.8152\n",
            "Epoch 6/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 193.0522 - mae: 11.4225 - val_loss: 160.2596 - val_mae: 10.2944\n",
            "Epoch 7/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 171.5204 - mae: 10.8000 - val_loss: 157.7703 - val_mae: 10.0645\n",
            "Epoch 8/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 163.1653 - mae: 10.5658 - val_loss: 155.2020 - val_mae: 9.9765\n",
            "Epoch 9/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 148.2085 - mae: 9.9740 - val_loss: 156.5409 - val_mae: 10.0263\n",
            "Epoch 10/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 153.3593 - mae: 10.2864 - val_loss: 151.0575 - val_mae: 9.7600\n",
            "Epoch 11/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 130.2976 - mae: 9.5303 - val_loss: 157.7636 - val_mae: 10.0265\n",
            "Epoch 12/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 139.9397 - mae: 9.8433 - val_loss: 155.0100 - val_mae: 9.9259\n",
            "Epoch 13/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 137.9319 - mae: 9.7653 - val_loss: 154.0126 - val_mae: 9.8277\n",
            "Epoch 14/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 132.9881 - mae: 9.4367 - val_loss: 151.0453 - val_mae: 9.6793\n",
            "Epoch 15/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 149.1982 - mae: 10.0050 - val_loss: 160.3466 - val_mae: 10.1053\n",
            "Epoch 16/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 119.6577 - mae: 8.9602 - val_loss: 159.9132 - val_mae: 10.0361\n",
            "Epoch 17/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 134.2286 - mae: 9.6392 - val_loss: 159.2190 - val_mae: 10.0950\n",
            "Epoch 18/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 127.8609 - mae: 9.2824 - val_loss: 152.5183 - val_mae: 9.7181\n",
            "Epoch 19/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 136.3980 - mae: 9.4991 - val_loss: 169.4350 - val_mae: 10.4198\n",
            "Epoch 20/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 127.6870 - mae: 9.3984 - val_loss: 159.1236 - val_mae: 9.9592\n",
            "Epoch 21/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 132.0682 - mae: 9.5874 - val_loss: 161.4483 - val_mae: 10.0472\n",
            "Epoch 22/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 115.5950 - mae: 8.7824 - val_loss: 155.1412 - val_mae: 9.8055\n",
            "Epoch 23/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 128.8703 - mae: 9.4261 - val_loss: 151.5496 - val_mae: 9.6414\n",
            "Epoch 24/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 121.7759 - mae: 9.0413 - val_loss: 163.2568 - val_mae: 10.1985\n",
            "Epoch 25/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 125.5998 - mae: 9.0065 - val_loss: 159.5573 - val_mae: 9.9003\n",
            "Epoch 26/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 113.7190 - mae: 8.7028 - val_loss: 155.6801 - val_mae: 9.7751\n",
            "Epoch 27/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 118.4870 - mae: 8.7845 - val_loss: 149.5913 - val_mae: 9.4762\n",
            "Epoch 28/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 116.8704 - mae: 8.7958 - val_loss: 160.5081 - val_mae: 10.0736\n",
            "Epoch 29/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 114.4737 - mae: 8.7143 - val_loss: 152.3826 - val_mae: 9.6533\n",
            "Epoch 30/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 109.9410 - mae: 8.4543 - val_loss: 149.0477 - val_mae: 9.4888\n",
            "Epoch 31/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 112.5200 - mae: 8.5634 - val_loss: 145.1499 - val_mae: 9.2834\n",
            "Epoch 32/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 119.4601 - mae: 8.7895 - val_loss: 149.2825 - val_mae: 9.4468\n",
            "Epoch 33/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 103.4572 - mae: 8.1636 - val_loss: 154.4685 - val_mae: 9.8019\n",
            "Epoch 34/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 106.1737 - mae: 8.4695 - val_loss: 148.7665 - val_mae: 9.4654\n",
            "Epoch 35/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 111.9865 - mae: 8.5687 - val_loss: 146.5043 - val_mae: 9.4332\n",
            "Epoch 36/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 110.8330 - mae: 8.5448 - val_loss: 150.7064 - val_mae: 9.6510\n",
            "Epoch 37/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 107.5399 - mae: 8.4034 - val_loss: 141.4213 - val_mae: 9.1685\n",
            "Epoch 38/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 109.5145 - mae: 8.4155 - val_loss: 135.8622 - val_mae: 8.8252\n",
            "Epoch 39/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 108.3433 - mae: 8.5581 - val_loss: 144.8144 - val_mae: 9.3905\n",
            "Epoch 40/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 99.4227 - mae: 8.0556 - val_loss: 140.7174 - val_mae: 9.2424\n",
            "Epoch 41/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 100.8521 - mae: 8.1822 - val_loss: 133.9905 - val_mae: 8.8770\n",
            "Epoch 42/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 88.0657 - mae: 7.6156 - val_loss: 132.5717 - val_mae: 8.7608\n",
            "Epoch 43/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 92.1241 - mae: 7.5543 - val_loss: 140.0914 - val_mae: 9.1980\n",
            "Epoch 44/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 91.7131 - mae: 7.8009 - val_loss: 130.5390 - val_mae: 8.7402\n",
            "Epoch 45/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 90.5755 - mae: 7.5617 - val_loss: 130.1968 - val_mae: 8.7046\n",
            "Epoch 46/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 86.7050 - mae: 7.4338 - val_loss: 127.9327 - val_mae: 8.5986\n",
            "Epoch 47/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 90.7234 - mae: 7.5861 - val_loss: 126.7511 - val_mae: 8.5303\n",
            "Epoch 48/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 85.5472 - mae: 7.3413 - val_loss: 123.3175 - val_mae: 8.2707\n",
            "Epoch 49/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 85.4396 - mae: 7.3090 - val_loss: 124.5740 - val_mae: 8.3175\n",
            "Epoch 50/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 74.4517 - mae: 6.8869 - val_loss: 123.8602 - val_mae: 8.3855\n",
            "Epoch 51/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 70.0905 - mae: 6.6650 - val_loss: 121.4755 - val_mae: 8.2648\n",
            "Epoch 52/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 72.1737 - mae: 6.6796 - val_loss: 120.0753 - val_mae: 8.1752\n",
            "Epoch 53/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 63.5082 - mae: 6.2084 - val_loss: 118.6366 - val_mae: 8.1526\n",
            "Epoch 54/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 61.7360 - mae: 6.1689 - val_loss: 118.7146 - val_mae: 8.1608\n",
            "Epoch 55/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 62.8353 - mae: 6.1743 - val_loss: 114.3773 - val_mae: 7.9021\n",
            "Epoch 56/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 62.2270 - mae: 6.1589 - val_loss: 115.2421 - val_mae: 7.9184\n",
            "Epoch 57/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 60.1836 - mae: 6.0969 - val_loss: 117.2068 - val_mae: 8.1361\n",
            "Epoch 58/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 54.6348 - mae: 5.7724 - val_loss: 126.4155 - val_mae: 8.6503\n",
            "Epoch 59/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 59.0789 - mae: 5.9952 - val_loss: 116.5025 - val_mae: 8.0918\n",
            "Epoch 60/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 49.2552 - mae: 5.5275 - val_loss: 113.7152 - val_mae: 7.9509\n",
            "Epoch 61/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 50.4436 - mae: 5.3402 - val_loss: 112.2824 - val_mae: 7.7711\n",
            "Epoch 62/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 45.0599 - mae: 5.1804 - val_loss: 103.2431 - val_mae: 7.3421\n",
            "Epoch 63/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 48.9937 - mae: 5.3884 - val_loss: 109.3849 - val_mae: 7.7055\n",
            "Epoch 64/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 42.0393 - mae: 4.9914 - val_loss: 109.8485 - val_mae: 7.6645\n",
            "Epoch 65/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 46.7909 - mae: 5.1873 - val_loss: 107.5862 - val_mae: 7.5589\n",
            "Epoch 66/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 44.2677 - mae: 4.8644 - val_loss: 110.5668 - val_mae: 7.7566\n",
            "Epoch 67/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 38.5108 - mae: 4.7860 - val_loss: 112.0896 - val_mae: 7.8745\n",
            "Epoch 68/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 43.0502 - mae: 5.0063 - val_loss: 106.6821 - val_mae: 7.5237\n",
            "Epoch 69/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 34.2884 - mae: 4.5286 - val_loss: 110.4217 - val_mae: 7.8187\n",
            "Epoch 70/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 49.1905 - mae: 5.2489 - val_loss: 114.9105 - val_mae: 8.0842\n",
            "Epoch 71/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 36.6732 - mae: 4.7018 - val_loss: 110.5233 - val_mae: 7.8487\n",
            "Epoch 72/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 36.7478 - mae: 4.6606 - val_loss: 105.7832 - val_mae: 7.5141\n",
            "Epoch 73/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 39.6807 - mae: 4.7163 - val_loss: 111.2063 - val_mae: 7.9142\n",
            "Epoch 74/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 36.6905 - mae: 4.6935 - val_loss: 106.2648 - val_mae: 7.5870\n",
            "Epoch 75/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 36.8883 - mae: 4.6399 - val_loss: 110.2289 - val_mae: 7.9266\n",
            "Epoch 76/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 36.8750 - mae: 4.6161 - val_loss: 106.3592 - val_mae: 7.6581\n",
            "Epoch 77/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 35.1347 - mae: 4.4025 - val_loss: 106.0832 - val_mae: 7.6213\n",
            "Epoch 78/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 30.5460 - mae: 4.1839 - val_loss: 103.4213 - val_mae: 7.4204\n",
            "Epoch 79/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 35.6382 - mae: 4.4408 - val_loss: 104.4361 - val_mae: 7.5008\n",
            "Epoch 80/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 32.6483 - mae: 4.4387 - val_loss: 110.4743 - val_mae: 7.9787\n",
            "processing fold # 2\n",
            "Epoch 1/80\n",
            "109/109 [==============================] - 1s 3ms/step - loss: 1539.9925 - mae: 34.5138 - val_loss: 1488.1246 - val_mae: 35.2248\n",
            "Epoch 2/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 975.4739 - mae: 26.0465 - val_loss: 699.9327 - val_mae: 22.4625\n",
            "Epoch 3/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 319.5153 - mae: 13.7432 - val_loss: 331.0203 - val_mae: 14.8814\n",
            "Epoch 4/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 218.9053 - mae: 11.8803 - val_loss: 301.4258 - val_mae: 14.2161\n",
            "Epoch 5/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 202.4471 - mae: 11.4355 - val_loss: 272.5415 - val_mae: 13.4705\n",
            "Epoch 6/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 159.9502 - mae: 10.1350 - val_loss: 266.4380 - val_mae: 13.3027\n",
            "Epoch 7/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 157.3034 - mae: 10.2825 - val_loss: 257.0326 - val_mae: 13.0521\n",
            "Epoch 8/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 159.1083 - mae: 10.2387 - val_loss: 248.5312 - val_mae: 12.8021\n",
            "Epoch 9/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 148.2007 - mae: 10.0195 - val_loss: 235.2733 - val_mae: 12.4304\n",
            "Epoch 10/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 151.3894 - mae: 10.1652 - val_loss: 244.7503 - val_mae: 12.6843\n",
            "Epoch 11/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 145.4276 - mae: 9.9366 - val_loss: 228.0877 - val_mae: 12.2196\n",
            "Epoch 12/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 159.5503 - mae: 10.4944 - val_loss: 214.7555 - val_mae: 11.8794\n",
            "Epoch 13/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 141.0444 - mae: 9.8108 - val_loss: 220.9931 - val_mae: 12.0401\n",
            "Epoch 14/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 138.8132 - mae: 9.6994 - val_loss: 215.1449 - val_mae: 11.8824\n",
            "Epoch 15/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 122.4727 - mae: 9.1590 - val_loss: 218.0255 - val_mae: 11.9616\n",
            "Epoch 16/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 125.9338 - mae: 9.2647 - val_loss: 211.7379 - val_mae: 11.7868\n",
            "Epoch 17/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 133.8908 - mae: 9.4182 - val_loss: 199.7236 - val_mae: 11.4400\n",
            "Epoch 18/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 133.0420 - mae: 9.3819 - val_loss: 201.3436 - val_mae: 11.5052\n",
            "Epoch 19/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 122.5990 - mae: 9.0760 - val_loss: 189.5847 - val_mae: 11.1529\n",
            "Epoch 20/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 133.4307 - mae: 9.3745 - val_loss: 170.3357 - val_mae: 10.5703\n",
            "Epoch 21/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 114.9007 - mae: 8.5927 - val_loss: 194.6961 - val_mae: 11.2676\n",
            "Epoch 22/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 115.0749 - mae: 8.7451 - val_loss: 190.4248 - val_mae: 11.1162\n",
            "Epoch 23/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 105.8423 - mae: 8.3056 - val_loss: 179.1736 - val_mae: 10.7963\n",
            "Epoch 24/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 102.5465 - mae: 8.1862 - val_loss: 164.9924 - val_mae: 10.3741\n",
            "Epoch 25/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 101.7631 - mae: 7.9933 - val_loss: 179.5998 - val_mae: 10.7501\n",
            "Epoch 26/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 102.9814 - mae: 8.2317 - val_loss: 171.0769 - val_mae: 10.4884\n",
            "Epoch 27/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 87.0041 - mae: 7.3046 - val_loss: 163.6551 - val_mae: 10.2311\n",
            "Epoch 28/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 89.4667 - mae: 7.2665 - val_loss: 144.3841 - val_mae: 9.6137\n",
            "Epoch 29/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 88.6474 - mae: 7.4669 - val_loss: 160.3666 - val_mae: 10.0847\n",
            "Epoch 30/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 90.9649 - mae: 7.4384 - val_loss: 157.9568 - val_mae: 9.9878\n",
            "Epoch 31/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 78.0086 - mae: 6.9715 - val_loss: 150.3310 - val_mae: 9.6951\n",
            "Epoch 32/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 75.2086 - mae: 6.9703 - val_loss: 166.2943 - val_mae: 10.1576\n",
            "Epoch 33/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 65.1193 - mae: 6.3191 - val_loss: 154.2558 - val_mae: 9.7744\n",
            "Epoch 34/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 62.8019 - mae: 6.2533 - val_loss: 149.4335 - val_mae: 9.6492\n",
            "Epoch 35/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 64.5032 - mae: 6.4613 - val_loss: 151.8492 - val_mae: 9.6242\n",
            "Epoch 36/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 55.2624 - mae: 5.7988 - val_loss: 134.8965 - val_mae: 9.1427\n",
            "Epoch 37/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 56.6706 - mae: 5.8765 - val_loss: 136.7250 - val_mae: 9.1428\n",
            "Epoch 38/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 54.9758 - mae: 5.7528 - val_loss: 144.3830 - val_mae: 9.3928\n",
            "Epoch 39/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 51.3665 - mae: 5.6603 - val_loss: 153.4476 - val_mae: 9.6010\n",
            "Epoch 40/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 45.2506 - mae: 5.2638 - val_loss: 147.9179 - val_mae: 9.4570\n",
            "Epoch 41/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 46.0649 - mae: 5.4057 - val_loss: 139.7742 - val_mae: 9.2004\n",
            "Epoch 42/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 42.4994 - mae: 5.0277 - val_loss: 138.7323 - val_mae: 9.1209\n",
            "Epoch 43/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 45.6524 - mae: 5.2095 - val_loss: 131.0644 - val_mae: 8.8843\n",
            "Epoch 44/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 38.9542 - mae: 4.8526 - val_loss: 130.3641 - val_mae: 8.8415\n",
            "Epoch 45/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 42.2637 - mae: 5.0127 - val_loss: 136.9957 - val_mae: 9.0584\n",
            "Epoch 46/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 38.5992 - mae: 4.7282 - val_loss: 139.9484 - val_mae: 9.1896\n",
            "Epoch 47/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 39.8824 - mae: 4.9162 - val_loss: 136.8950 - val_mae: 9.0665\n",
            "Epoch 48/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 40.9915 - mae: 4.7773 - val_loss: 124.2696 - val_mae: 8.6574\n",
            "Epoch 49/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 35.3932 - mae: 4.6894 - val_loss: 134.6082 - val_mae: 9.0216\n",
            "Epoch 50/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 38.4887 - mae: 4.6389 - val_loss: 127.7041 - val_mae: 8.7519\n",
            "Epoch 51/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 35.7169 - mae: 4.5776 - val_loss: 142.6560 - val_mae: 9.3365\n",
            "Epoch 52/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 34.9649 - mae: 4.4615 - val_loss: 144.9650 - val_mae: 9.3762\n",
            "Epoch 53/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 36.3246 - mae: 4.5106 - val_loss: 127.7681 - val_mae: 8.8431\n",
            "Epoch 54/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 33.7524 - mae: 4.4609 - val_loss: 134.0265 - val_mae: 9.0074\n",
            "Epoch 55/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 33.9545 - mae: 4.4911 - val_loss: 129.1044 - val_mae: 8.9371\n",
            "Epoch 56/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 29.5034 - mae: 4.2067 - val_loss: 137.4048 - val_mae: 9.1373\n",
            "Epoch 57/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 31.3589 - mae: 4.2429 - val_loss: 130.7026 - val_mae: 9.0142\n",
            "Epoch 58/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 27.7274 - mae: 4.0045 - val_loss: 132.2515 - val_mae: 9.0116\n",
            "Epoch 59/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 33.4141 - mae: 4.3362 - val_loss: 132.1944 - val_mae: 8.9806\n",
            "Epoch 60/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 26.9063 - mae: 3.9978 - val_loss: 126.1540 - val_mae: 8.8550\n",
            "Epoch 61/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 32.7967 - mae: 4.3934 - val_loss: 126.5732 - val_mae: 8.9464\n",
            "Epoch 62/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 27.0084 - mae: 4.0441 - val_loss: 141.5675 - val_mae: 9.3218\n",
            "Epoch 63/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 30.4574 - mae: 4.1029 - val_loss: 127.3457 - val_mae: 8.9299\n",
            "Epoch 64/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 25.2894 - mae: 3.6936 - val_loss: 124.2562 - val_mae: 8.8111\n",
            "Epoch 65/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 28.8007 - mae: 4.0485 - val_loss: 128.5473 - val_mae: 8.9098\n",
            "Epoch 66/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 30.0349 - mae: 4.0830 - val_loss: 125.9331 - val_mae: 8.8541\n",
            "Epoch 67/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 25.4304 - mae: 3.7487 - val_loss: 126.5582 - val_mae: 8.9283\n",
            "Epoch 68/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 28.1800 - mae: 4.0305 - val_loss: 132.0779 - val_mae: 9.0873\n",
            "Epoch 69/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 23.9443 - mae: 3.6368 - val_loss: 126.5875 - val_mae: 8.9601\n",
            "Epoch 70/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 26.7425 - mae: 3.8479 - val_loss: 122.6304 - val_mae: 8.9278\n",
            "Epoch 71/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 25.0286 - mae: 3.8876 - val_loss: 134.8092 - val_mae: 9.1898\n",
            "Epoch 72/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 24.6916 - mae: 3.7648 - val_loss: 130.9761 - val_mae: 9.1539\n",
            "Epoch 73/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 22.0614 - mae: 3.5818 - val_loss: 127.1400 - val_mae: 8.9393\n",
            "Epoch 74/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 21.4529 - mae: 3.5595 - val_loss: 130.7801 - val_mae: 9.1914\n",
            "Epoch 75/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 22.2882 - mae: 3.5076 - val_loss: 126.4491 - val_mae: 8.9966\n",
            "Epoch 76/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 20.8405 - mae: 3.6207 - val_loss: 133.9392 - val_mae: 9.3960\n",
            "Epoch 77/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 23.4146 - mae: 3.7216 - val_loss: 133.2792 - val_mae: 9.4214\n",
            "Epoch 78/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 22.4318 - mae: 3.3656 - val_loss: 132.6591 - val_mae: 9.1756\n",
            "Epoch 79/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 22.9995 - mae: 3.6561 - val_loss: 135.2716 - val_mae: 9.3421\n",
            "Epoch 80/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 21.6228 - mae: 3.5008 - val_loss: 135.2248 - val_mae: 9.4458\n",
            "processing fold # 3\n",
            "Epoch 1/80\n",
            "109/109 [==============================] - 1s 3ms/step - loss: 1887.4778 - mae: 40.2079 - val_loss: 485.0949 - val_mae: 19.0159\n",
            "Epoch 2/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 1137.0427 - mae: 30.1532 - val_loss: 237.1163 - val_mae: 12.1609\n",
            "Epoch 3/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 387.1615 - mae: 15.7533 - val_loss: 118.6887 - val_mae: 8.7876\n",
            "Epoch 4/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 246.5353 - mae: 12.3788 - val_loss: 121.6266 - val_mae: 8.9404\n",
            "Epoch 5/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 207.7474 - mae: 11.7580 - val_loss: 130.8806 - val_mae: 9.1793\n",
            "Epoch 6/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 184.8193 - mae: 11.2236 - val_loss: 144.2798 - val_mae: 9.5326\n",
            "Epoch 7/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 183.0851 - mae: 11.2416 - val_loss: 161.2906 - val_mae: 9.9674\n",
            "Epoch 8/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 154.9580 - mae: 10.1946 - val_loss: 173.2459 - val_mae: 10.3702\n",
            "Epoch 9/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 161.6269 - mae: 10.4404 - val_loss: 183.4452 - val_mae: 10.7246\n",
            "Epoch 10/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 147.9694 - mae: 9.9826 - val_loss: 195.2135 - val_mae: 11.0718\n",
            "Epoch 11/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 144.0594 - mae: 9.8658 - val_loss: 197.6277 - val_mae: 11.1664\n",
            "Epoch 12/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 151.4519 - mae: 10.0967 - val_loss: 216.6259 - val_mae: 11.6812\n",
            "Epoch 13/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 143.8286 - mae: 9.8048 - val_loss: 215.5726 - val_mae: 11.6696\n",
            "Epoch 14/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 145.6801 - mae: 9.7112 - val_loss: 225.1730 - val_mae: 11.9711\n",
            "Epoch 15/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 129.3251 - mae: 9.0669 - val_loss: 238.0187 - val_mae: 12.2566\n",
            "Epoch 16/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 134.2137 - mae: 9.4474 - val_loss: 211.9112 - val_mae: 11.6611\n",
            "Epoch 17/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 132.2393 - mae: 9.2014 - val_loss: 201.6587 - val_mae: 11.3801\n",
            "Epoch 18/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 120.0484 - mae: 8.8635 - val_loss: 218.8162 - val_mae: 11.8400\n",
            "Epoch 19/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 123.4559 - mae: 8.9829 - val_loss: 215.5179 - val_mae: 11.8094\n",
            "Epoch 20/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 124.2694 - mae: 9.1132 - val_loss: 229.1050 - val_mae: 12.1650\n",
            "Epoch 21/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 128.3143 - mae: 9.1347 - val_loss: 231.5798 - val_mae: 12.2111\n",
            "Epoch 22/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 116.1595 - mae: 8.6998 - val_loss: 193.5744 - val_mae: 11.2036\n",
            "Epoch 23/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 116.8979 - mae: 8.9052 - val_loss: 209.4660 - val_mae: 11.6592\n",
            "Epoch 24/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 126.2492 - mae: 9.1096 - val_loss: 219.9894 - val_mae: 11.9205\n",
            "Epoch 25/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 112.7608 - mae: 8.6709 - val_loss: 236.1999 - val_mae: 12.2479\n",
            "Epoch 26/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 126.4943 - mae: 9.0143 - val_loss: 218.4713 - val_mae: 11.8272\n",
            "Epoch 27/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 124.9673 - mae: 9.0527 - val_loss: 238.9033 - val_mae: 12.3189\n",
            "Epoch 28/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 126.8994 - mae: 8.9559 - val_loss: 211.5855 - val_mae: 11.6367\n",
            "Epoch 29/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 124.2189 - mae: 9.0175 - val_loss: 209.7840 - val_mae: 11.6149\n",
            "Epoch 30/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 111.8198 - mae: 8.3588 - val_loss: 212.1633 - val_mae: 11.6892\n",
            "Epoch 31/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 104.8353 - mae: 8.3061 - val_loss: 220.4612 - val_mae: 11.9155\n",
            "Epoch 32/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 113.2573 - mae: 8.4667 - val_loss: 213.1107 - val_mae: 11.7382\n",
            "Epoch 33/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 100.6975 - mae: 8.0082 - val_loss: 238.9630 - val_mae: 12.4004\n",
            "Epoch 34/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 114.0712 - mae: 8.5500 - val_loss: 229.3372 - val_mae: 12.1374\n",
            "Epoch 35/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 121.8243 - mae: 8.7608 - val_loss: 236.1274 - val_mae: 12.3740\n",
            "Epoch 36/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 112.0304 - mae: 8.2299 - val_loss: 227.9552 - val_mae: 12.1722\n",
            "Epoch 37/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 104.4922 - mae: 8.0304 - val_loss: 212.9556 - val_mae: 11.8046\n",
            "Epoch 38/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 109.8780 - mae: 8.3392 - val_loss: 219.2113 - val_mae: 11.9530\n",
            "Epoch 39/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 103.7577 - mae: 7.9872 - val_loss: 218.6050 - val_mae: 11.9506\n",
            "Epoch 40/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 85.4034 - mae: 7.3192 - val_loss: 204.3716 - val_mae: 11.6081\n",
            "Epoch 41/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 113.0566 - mae: 8.3147 - val_loss: 215.9648 - val_mae: 11.9291\n",
            "Epoch 42/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 92.8567 - mae: 7.5911 - val_loss: 190.5567 - val_mae: 11.3023\n",
            "Epoch 43/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 86.0645 - mae: 7.3576 - val_loss: 208.7995 - val_mae: 11.7725\n",
            "Epoch 44/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 89.2666 - mae: 7.3721 - val_loss: 215.4382 - val_mae: 11.9814\n",
            "Epoch 45/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 89.2855 - mae: 7.2610 - val_loss: 219.7537 - val_mae: 12.0541\n",
            "Epoch 46/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 87.7401 - mae: 7.3784 - val_loss: 196.3624 - val_mae: 11.4176\n",
            "Epoch 47/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 85.3971 - mae: 7.1477 - val_loss: 196.1002 - val_mae: 11.4889\n",
            "Epoch 48/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 77.5669 - mae: 6.8953 - val_loss: 210.1882 - val_mae: 11.9012\n",
            "Epoch 49/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 80.7867 - mae: 7.1246 - val_loss: 205.3280 - val_mae: 11.7598\n",
            "Epoch 50/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 83.1235 - mae: 7.1006 - val_loss: 201.5514 - val_mae: 11.6766\n",
            "Epoch 51/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 75.2045 - mae: 6.9428 - val_loss: 181.8081 - val_mae: 11.1059\n",
            "Epoch 52/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 74.1256 - mae: 6.7157 - val_loss: 205.6304 - val_mae: 11.8026\n",
            "Epoch 53/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 71.5750 - mae: 6.5960 - val_loss: 191.3503 - val_mae: 11.3651\n",
            "Epoch 54/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 69.6734 - mae: 6.5058 - val_loss: 197.9726 - val_mae: 11.5436\n",
            "Epoch 55/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 65.2102 - mae: 6.3642 - val_loss: 203.0552 - val_mae: 11.6659\n",
            "Epoch 56/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 69.2416 - mae: 6.5084 - val_loss: 201.0143 - val_mae: 11.5648\n",
            "Epoch 57/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 67.7009 - mae: 6.4403 - val_loss: 189.2373 - val_mae: 11.2793\n",
            "Epoch 58/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 64.0412 - mae: 6.3920 - val_loss: 184.1414 - val_mae: 11.1346\n",
            "Epoch 59/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 58.9224 - mae: 6.0630 - val_loss: 211.7332 - val_mae: 11.9393\n",
            "Epoch 60/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 55.9566 - mae: 5.8738 - val_loss: 193.3399 - val_mae: 11.4161\n",
            "Epoch 61/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 63.5235 - mae: 6.3323 - val_loss: 198.2238 - val_mae: 11.5523\n",
            "Epoch 62/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 62.7363 - mae: 6.3257 - val_loss: 184.6447 - val_mae: 11.1694\n",
            "Epoch 63/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 53.9660 - mae: 5.8010 - val_loss: 177.8377 - val_mae: 10.9391\n",
            "Epoch 64/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 54.6267 - mae: 5.7842 - val_loss: 182.5209 - val_mae: 11.0770\n",
            "Epoch 65/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 53.8485 - mae: 5.8874 - val_loss: 190.8925 - val_mae: 11.3951\n",
            "Epoch 66/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 54.5855 - mae: 5.8872 - val_loss: 181.7950 - val_mae: 11.0920\n",
            "Epoch 67/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 53.2390 - mae: 5.5614 - val_loss: 178.9935 - val_mae: 10.9781\n",
            "Epoch 68/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 46.8465 - mae: 5.5223 - val_loss: 184.6021 - val_mae: 11.1895\n",
            "Epoch 69/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 46.8841 - mae: 5.4507 - val_loss: 185.7756 - val_mae: 11.2346\n",
            "Epoch 70/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 43.3995 - mae: 5.1398 - val_loss: 187.1975 - val_mae: 11.3172\n",
            "Epoch 71/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 41.8319 - mae: 4.9985 - val_loss: 154.1402 - val_mae: 10.2258\n",
            "Epoch 72/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 40.7294 - mae: 5.0123 - val_loss: 142.8457 - val_mae: 9.7871\n",
            "Epoch 73/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 43.0408 - mae: 5.1683 - val_loss: 175.5489 - val_mae: 10.9089\n",
            "Epoch 74/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 50.8225 - mae: 5.4651 - val_loss: 146.2211 - val_mae: 9.9188\n",
            "Epoch 75/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 43.5923 - mae: 5.2100 - val_loss: 145.9071 - val_mae: 9.9511\n",
            "Epoch 76/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 41.8124 - mae: 5.0638 - val_loss: 143.0473 - val_mae: 9.8080\n",
            "Epoch 77/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 39.4663 - mae: 5.0065 - val_loss: 150.8785 - val_mae: 10.1180\n",
            "Epoch 78/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 37.9062 - mae: 4.7707 - val_loss: 123.2761 - val_mae: 9.1410\n",
            "Epoch 79/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 40.7247 - mae: 4.9506 - val_loss: 143.0048 - val_mae: 9.8619\n",
            "Epoch 80/80\n",
            "109/109 [==============================] - 0s 2ms/step - loss: 39.7730 - mae: 4.9906 - val_loss: 128.7638 - val_mae: 9.2359\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOcsa1tavhkU"
      },
      "source": [
        "average_mae_history = [np.mean([x[i] for x in all_mae_histories]) for i in range(num_epochs)]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "qtRIcqr5vzu7",
        "outputId": "438ab44e-8751-45d9-cad0-665adda4e048"
      },
      "source": [
        "plt.plot(range(len(average_mae_history)), average_mae_history)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation MAE')\n",
        "plt.show()\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urY9xuSJwT2x",
        "outputId": "43ca75a8-9fb6-4de1-c95f-7faef391ee18"
      },
      "source": [
        "test_mse_score, test_mae_score = model.evaluate(test_data, test_labels)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 0s 2ms/step - loss: 121.2602 - mae: 8.7014\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_urijxbcwYs7",
        "outputId": "5f872c7a-fb72-4429-c082-8fdcf5883bd0"
      },
      "source": [
        "test_mae_score"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11.646957397460938"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    }
  ]
}